{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Data Workflow Notebook\n",
    "\n",
    "Modular workflow where you can run individual steps independently.\n",
    "Run cells in order or skip any steps you don't need.\n",
    "\n",
    "Each step shows dataframe views and statistics for inspection.\n",
    "\n",
    "## Quick Start\n",
    "- Run **Setup** cell first\n",
    "- Then run any combination of Step 1-4 cells\n",
    "- Skip cells you don't want to execute\n",
    "- Each cell is self-contained and shows results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd27 Setup\n",
    "\n",
    "Run this cell first to import modules and define helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Add current directory to path for local imports\n",
    "sys.path.append(\".\")\n",
    "\n",
    "# Import our workflow modules\n",
    "from fetch_affordable_housing_data import update_local_data, verify_and_fetch_hpd_data\n",
    "from query_ll44_funding import query_and_add_financing\n",
    "from query_dob_filings import query_dob_filings\n",
    "from query_co_filings import query_co_filings\n",
    "from HPD_DOB_Join_On_BIN import create_separate_timelines\n",
    "from create_timeline_chart import create_timeline_chart, create_financing_charts\n",
    "from data_quality import quality_tracker\n",
    "\n",
    "print(\"\u2705 All imports successful\")\n",
    "\n",
    "# Helper functions\n",
    "def _normalize_bin(bin_value) -> Optional[str]:\n",
    "    \"\"\"Normalize BIN to a clean string.\"\"\"\n",
    "    if pd.isna(bin_value):\n",
    "        return None\n",
    "    try:\n",
    "        return str(int(float(bin_value)))\n",
    "    except (TypeError, ValueError):\n",
    "        value = str(bin_value).strip()\n",
    "        return value or None\n",
    "\n",
    "def _write_bin_file(source_csv: Path, output_txt: Path) -> Path:\n",
    "    \"\"\"Extract BINs from a CSV and write them to a text file for CO searches.\"\"\"\n",
    "    df = pd.read_csv(source_csv)\n",
    "    candidate_cols = [col for col in df.columns if col.lower() in (\"bin\", \"bin_normalized\")]\n",
    "    if not candidate_cols:\n",
    "        raise SystemExit(f\"Could not find a BIN column in {source_csv}\")\n",
    "\n",
    "    bins = [_normalize_bin(val) for val in df[candidate_cols[0]].dropna()]\n",
    "    bins = sorted({b for b in bins if b})\n",
    "\n",
    "    output_txt.parent.mkdir(parents=True, exist_ok=True)\n",
    "    output_txt.write_text(\"\\n\".join(bins))\n",
    "    print(f\"Wrote {len(bins)} BINs to {output_txt}\")\n",
    "    return output_txt\n",
    "\n",
    "print(\"\u2705 Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udce5 Step 1: Fetch HPD Data\n",
    "\n",
    "Load or refresh the HPD affordable housing dataset.\n",
    "\n",
    "**Options:**\n",
    "- Set `refresh_data = True` to fetch fresh data\n",
    "- Set `refresh_data = False` to use existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 Configuration\n",
    "refresh_data = False  # Set to True to fetch fresh HPD data\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 1: FETCH HPD DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Start quality tracking\n",
    "quality_tracker.start_processing()\n",
    "\n",
    "if refresh_data:\n",
    "    print(\"Fetching fresh HPD data from NYC Open Data...\")\n",
    "    hpd_df = update_local_data()\n",
    "else:\n",
    "    print(\"Verifying local HPD data against API...\")\n",
    "    hpd_df = verify_and_fetch_hpd_data()\n",
    "\n",
    "hpd_csv = Path(\"data/raw/Affordable_Housing_Production_by_Building.csv\")\n",
    "\n",
    "if not hpd_csv.exists():\n",
    "    raise SystemExit(f\"HPD dataset not found at {hpd_csv}\")\n",
    "\n",
    "# Record initial dataset size\n",
    "quality_tracker.analyze_hpd_data(hpd_df, \"Full_HPD_Dataset\")\n",
    "quality_tracker.record_pipeline_stage(\"raw_hpd_data\", len(hpd_df), \"Raw HPD affordable housing dataset\")\n",
    "\n",
    "print(f\"\u2705 Step 1 complete: {len(hpd_df):,} records loaded\")\n",
    "print(f\"\ud83d\udcc1 Data location: {hpd_csv}\")\n",
    "\n",
    "# Display the dataframe\n",
    "print(\"\\n\ud83d\udd0d HPD Dataset Overview:\")\n",
    "print(f\"Shape: {hpd_df.shape}\")\n",
    "print(\"\\nColumns:\")\n",
    "for col in hpd_df.columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(\"\\n\ud83d\udcca Sample Data:\")\n",
    "display(hpd_df.head())\n",
    "\n",
    "print(\"\\n\ud83d\udcc8 Basic Statistics:\")\n",
    "display(hpd_df.describe(include=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcb0 Step 2: Add Financing Classification\n",
    "\n",
    "Classify projects by financing type (HPD vs Private).\n",
    "\n",
    "**Depends on:** Step 1\n",
    "**Options:**\n",
    "- Set `skip_financing = True` to skip this step\n",
    "- Customize output path if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 Configuration\n",
    "skip_financing = False  # Set to True to skip financing classification\n",
    "financing_output_path = None  # Custom output path (None = auto-generate)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 2: ADD FINANCING CLASSIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if skip_financing:\n",
    "    print(\"\u23ed\ufe0f Skipping financing classification as requested.\")\n",
    "    financing_df = hpd_df.copy()\n",
    "    quality_tracker.record_pipeline_stage(\"after_financing_skip\", len(financing_df), \"Financing classification skipped\")\n",
    "    building_csv = hpd_csv\n",
    "else:\n",
    "    output_path = Path(financing_output_path) if financing_output_path else Path(\n",
    "        \"data/processed/Affordable_Housing_Production_by_Building_with_financing.csv\"\n",
    "    )\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"Classifying financing types -> {output_path}\")\n",
    "    financing_df = query_and_add_financing(str(hpd_csv), output_path=str(output_path))\n",
    "    building_csv = output_path\n",
    "\n",
    "    # Record dataset after financing classification\n",
    "    quality_tracker.analyze_hpd_data(financing_df, \"Filtered_HPD\")\n",
    "    quality_tracker.record_pipeline_stage(\"after_financing\", len(financing_df), \"Added LL44 financing classification\")\n",
    "\n",
    "print(f\"\u2705 Step 2 complete: {len(financing_df):,} records with financing classification\")\n",
    "\n",
    "# Display the dataframe with financing info\n",
    "print(\"\\n\ud83d\udd0d Financing Classification Results:\")\n",
    "print(f\"Shape: {financing_df.shape}\")\n",
    "\n",
    "# Check if financing columns were added\n",
    "financing_cols = [col for col in financing_df.columns if \"financ\" in col.lower() or \"ll44\" in col.lower()]\n",
    "print(f\"\\nFinancing-related columns: {financing_cols}\")\n",
    "\n",
    "print(\"\\n\ud83d\udcca Sample Data with Financing:\")\n",
    "display(financing_df.head())\n",
    "\n",
    "# Show financing type distribution\n",
    "if financing_cols:\n",
    "    for col in financing_cols:\n",
    "        if col in financing_df.columns:\n",
    "            print(f\"\\n\ud83d\udcc8 Distribution of {col}:\")\n",
    "            display(financing_df[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfd7\ufe0f Step 3A: Query DOB Filings\n",
    "\n",
    "Search for DOB New Building filings.\n",
    "\n",
    "**Depends on:** Step 2\n",
    "**Options:**\n",
    "- Set `skip_dob = True` to use existing DOB data\n",
    "- Set `use_bbl_fallback = False` to disable BBL fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3A Configuration\n",
    "skip_dob = False  # Set to True to use existing DOB data\n",
    "use_bbl_fallback = True  # Set to False to disable BBL fallback\n",
    "dob_output_path = None  # Custom DOB output path\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 3A: QUERY DOB FILINGS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "dob_output = Path(dob_output_path) if dob_output_path else Path(\n",
    "    f\"data/processed/{building_csv.stem}_dob_filings.csv\"\n",
    ")\n",
    "dob_output.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check for existing DOB files when skipping\n",
    "if skip_dob:\n",
    "    print(\"\u23ed\ufe0f Using existing DOB data\")\n",
    "    # Look for existing files\n",
    "    alt_dob_path = Path(f\"data/external/{building_csv.stem}_dob_filings.csv\")\n",
    "    if dob_output.exists():\n",
    "        print(f\"\ud83d\udcc1 Using existing DOB data at {dob_output}\")\n",
    "        dob_df = pd.read_csv(dob_output)\n",
    "    elif alt_dob_path.exists():\n",
    "        print(f\"\ud83d\udcc1 Using existing DOB data from external folder: {alt_dob_path}\")\n",
    "        dob_output = alt_dob_path\n",
    "        dob_df = pd.read_csv(dob_output)\n",
    "    else:\n",
    "        print(\"\u26a0\ufe0f No existing DOB data found\")\n",
    "        dob_df = None\n",
    "        dob_output = None\n",
    "else:\n",
    "    print(f\"\ud83d\udd0d Querying DOB APIs using {building_csv} -> {dob_output}\")\n",
    "    print(\"   This may take several minutes...\")\n",
    "    query_dob_filings(\n",
    "        str(building_csv),\n",
    "        output_path=str(dob_output),\n",
    "        use_bbl_fallback=use_bbl_fallback,\n",
    "    )\n",
    "    print(f\"\u2705 DOB query completed: {dob_output}\")\n",
    "    dob_df = pd.read_csv(dob_output)\n",
    "\n",
    "# Display DOB data if available\n",
    "if dob_df is not None:\n",
    "    print(f\"\ud83d\udcca DOB Filings Data: {dob_df.shape[0]} records\")\n",
    "    print(\"Columns:\")\n",
    "    for col in dob_df.columns:\n",
    "        print(f\"  - {col}\")\n",
    "    \n",
    "    print(\"\\n\ud83d\udcca Sample DOB Data:\")\n",
    "    display(dob_df.head())\n",
    "    \n",
    "    # Show some statistics\n",
    "    if \"filing_date\" in dob_df.columns:\n",
    "        print(\"\\n\ud83d\udcc8 DOB Filing Date Statistics:\")\n",
    "        display(dob_df[\"filing_date\"].describe())\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f No DOB data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfdb\ufe0f Step 3B: Query Certificate of Occupancy\n",
    "\n",
    "Search for Certificate of Occupancy filings.\n",
    "\n",
    "**Depends on:** Step 2\n",
    "**Options:**\n",
    "- Set `skip_co = True` to use existing CO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3B Configuration\n",
    "skip_co = False  # Set to True to use existing CO data\n",
    "co_output_path = None  # Custom CO output path\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 3B: QUERY CERTIFICATE OF OCCUPANCY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Generate BIN file for CO searches\n",
    "bin_output = Path(\"data/processed/workflow_bins.txt\")\n",
    "bin_file = _write_bin_file(building_csv, bin_output)\n",
    "\n",
    "print(f\"\\n\ud83d\udccb BIN file created: {bin_file}\")\n",
    "print(f\"Contains {len(bin_file.read_text().split())} BINs\")\n",
    "\n",
    "co_output = Path(co_output_path) if co_output_path else Path(\n",
    "    f\"data/processed/{bin_file.stem}_co_filings.csv\"\n",
    ")\n",
    "co_output.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if skip_co:\n",
    "    print(\"\u23ed\ufe0f Using existing CO data\")\n",
    "    # Look for existing CO files\n",
    "    alt_co_path = Path(f\"data/external/{bin_file.stem}_co_filings.csv\")\n",
    "    if co_output.exists():\n",
    "        print(f\"\ud83d\udcc1 Using existing CO data at {co_output}\")\n",
    "        co_df = pd.read_csv(co_output)\n",
    "    elif alt_co_path.exists():\n",
    "        print(f\"\ud83d\udcc1 Using existing CO data from external folder: {alt_co_path}\")\n",
    "        co_output = alt_co_path\n",
    "        co_df = pd.read_csv(co_output)\n",
    "    else:\n",
    "        print(\"\u26a0\ufe0f No existing CO data found\")\n",
    "        co_df = None\n",
    "        co_output = None\n",
    "else:\n",
    "    print(f\"\ud83c\udfdb\ufe0f Querying CO APIs using {bin_file} -> {co_output}\")\n",
    "    query_co_filings(str(bin_file), output_path=str(co_output))\n",
    "    co_df = pd.read_csv(co_output)\n",
    "\n",
    "# Display CO data if available\n",
    "if co_df is not None:\n",
    "    print(f\"\ud83d\udcca Certificate of Occupancy Data: {co_df.shape[0]} records\")\n",
    "    print(\"Columns:\")\n",
    "    for col in co_df.columns:\n",
    "        print(f\"  - {col}\")\n",
    "    \n",
    "    print(\"\\n\ud83d\udcca Sample CO Data:\")\n",
    "    display(co_df.head())\n",
    "    \n",
    "    # Show some statistics\n",
    "    if \"issue_date\" in co_df.columns:\n",
    "        print(\"\\n\ud83d\udcc8 CO Issue Date Statistics:\")\n",
    "        display(co_df[\"issue_date\"].describe())\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f No CO data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Step 4: Generate Timelines and Charts\n",
    "\n",
    "Create timeline visualizations from enriched data.\n",
    "\n",
    "**Depends on:** Steps 2, 3A\n",
    "**Options:**\n",
    "- Set `skip_join = True` to skip timeline creation\n",
    "- Set `skip_charts = True` to skip chart generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 Configuration\n",
    "skip_join = False   # Set to True to skip timeline creation\n",
    "skip_charts = False # Set to True to skip chart generation\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 4: GENERATE TIMELINES AND CHARTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if skip_join:\n",
    "    print(\"\u23ed\ufe0f Skipping timeline join step.\")\n",
    "else:\n",
    "    if dob_output is None or not dob_output.exists():\n",
    "        print(\"\u26a0\ufe0f No DOB data available; skipping timeline creation.\")\n",
    "    else:\n",
    "        print(\"\ud83d\udd17 Building timelines...\")\n",
    "        create_separate_timelines(\n",
    "            str(building_csv),\n",
    "            str(dob_output),\n",
    "            str(co_output) if co_output else None,\n",
    "        )\n",
    "        \n",
    "        # Load and display timeline data\n",
    "        hpd_timeline = Path(str(building_csv).replace(\".csv\", \"_hpd_financed_timeline.csv\"))\n",
    "        private_timeline = Path(str(building_csv).replace(\".csv\", \"_privately_financed_timeline.csv\"))\n",
    "        \n",
    "        if hpd_timeline.exists():\n",
    "            hpd_timeline_df = pd.read_csv(hpd_timeline)\n",
    "            print(f\"\\n\ud83d\udcca HPD Financed Timeline Data ({hpd_timeline_df.shape[0]} records):\")\n",
    "            display(hpd_timeline_df.head())\n",
    "            \n",
    "            # Show event type distribution\n",
    "            if \"event_type\" in hpd_timeline_df.columns:\n",
    "                print(\"\\n\ud83d\udcc8 Event Types in HPD Timeline:\")\n",
    "                display(hpd_timeline_df[\"event_type\"].value_counts())\n",
    "        \n",
    "        if private_timeline.exists():\n",
    "            private_timeline_df = pd.read_csv(private_timeline)\n",
    "            print(f\"\\n\ud83d\udcca Privately Financed Timeline Data ({private_timeline_df.shape[0]} records):\")\n",
    "            display(private_timeline_df.head())\n",
    "            \n",
    "            # Show event type distribution\n",
    "            if \"event_type\" in private_timeline_df.columns:\n",
    "                print(\"\\n\ud83d\udcc8 Event Types in Private Timeline:\")\n",
    "                display(private_timeline_df[\"event_type\"].value_counts())\n",
    "\n",
    "if skip_charts:\n",
    "    print(\"\u23ed\ufe0f Skipping chart generation.\")\n",
    "else:\n",
    "    # Charts\n",
    "    print(\"\\n\ud83d\udcc8 Generating charts...\")\n",
    "    default_timeline_stem = \"Affordable_Housing_Production_by_Building_with_financing\"\n",
    "    if Path(building_csv).name == f\"{default_timeline_stem}.csv\":\n",
    "        create_financing_charts()\n",
    "        print(\"\u2705 Created financing-specific charts\")\n",
    "    else:\n",
    "        hpd_timeline = Path(str(building_csv).replace(\".csv\", \"_hpd_financed_timeline.csv\"))\n",
    "        private_timeline = Path(str(building_csv).replace(\".csv\", \"_privately_financed_timeline.csv\"))\n",
    "        \n",
    "        if hpd_timeline.exists():\n",
    "            create_timeline_chart(str(hpd_timeline))\n",
    "            print(f\"\u2705 Created HPD financed timeline chart\")\n",
    "        else:\n",
    "            print(f\"\u26a0\ufe0f No HPD financed timeline found; skipping.\")\n",
    "\n",
    "        if private_timeline.exists():\n",
    "            create_timeline_chart(str(private_timeline))\n",
    "            print(f\"\u2705 Created privately financed timeline chart\")\n",
    "        else:\n",
    "            print(f\"\u26a0\ufe0f No privately financed timeline found; skipping.\")\n",
    "\n",
    "print(\"\\n\u2705 Step 4 complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udccb Final Summary\n",
    "\n",
    "Generate data quality report and workflow summary.\n",
    "\n",
    "**Optional:** Run this at the end to see final statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\ud83d\udcca FINAL DATA QUALITY REPORT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Generate final data quality report and Sankey diagram\n",
    "quality_tracker.end_processing()\n",
    "report_filename = quality_tracker.save_report_to_file(\"notebook_workflow\")\n",
    "sankey_filename = quality_tracker.generate_sankey_diagram()\n",
    "quality_tracker.print_report()\n",
    "\n",
    "print(\"\\n\ud83c\udf89 WORKFLOW COMPLETED!\")\n",
    "print(f\"\ud83d\udcca Data quality report: {report_filename}\")\n",
    "if sankey_filename:\n",
    "    print(f\"\ud83d\udcca Sankey diagram: {sankey_filename}\")\n",
    "\n",
    "# Summary of what we accomplished\n",
    "print(\"\\n\ud83d\udccb WORKFLOW SUMMARY:\")\n",
    "try:\n",
    "    print(f\"\u2022 HPD Records Processed: {len(hpd_df):,}\")\n",
    "except NameError:\n",
    "    print(\"\u2022 HPD Records: Step 1 not run\")\n",
    "try:\n",
    "    print(f\"\u2022 Records with Financing: {len(financing_df):,}\")\n",
    "except NameError:\n",
    "    print(\"\u2022 Records with Financing: Step 2 not run\")\n",
    "try:\n",
    "    if dob_df is not None:\n",
    "        print(f\"\u2022 DOB Filings Found: {len(dob_df):,}\")\n",
    "    else:\n",
    "        print(\"\u2022 DOB Filings: No data\")\n",
    "except NameError:\n",
    "    print(\"\u2022 DOB Filings: Step 3A not run\")\n",
    "try:\n",
    "    if co_df is not None:\n",
    "        print(f\"\u2022 CO Filings Found: {len(co_df):,}\")\n",
    "    else:\n",
    "        print(\"\u2022 CO Filings: No data\")\n",
    "except NameError:\n",
    "    print(\"\u2022 CO Filings: Step 3B not run\")\n",
    "\n",
    "print(\"\\n\u2705 Notebook workflow complete!\")\n",
    "print(\"Each step showed dataframe views for inspection.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}