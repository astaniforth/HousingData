{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Data Workflow Notebook\n",
    "\n",
    "Modular workflow where you can run individual steps independently.\n",
    "Run cells in order or skip any steps you don't need.\n",
    "\n",
    "Each step shows dataframe views and statistics for inspection.\n",
    "\n",
    "## Quick Start\n",
    "- Run **Setup** cell first\n",
    "- Then run any combination of Step 1-4 cells\n",
    "- Skip cells you don't want to execute\n",
    "- Each cell is self-contained and shows results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup\n",
    "\n",
    "Run this cell first to import modules and define helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Add current directory to path for local imports\n",
    "sys.path.append(\".\")\n",
    "\n",
    "# Import our workflow modules\n",
    "from fetch_affordable_housing_data import update_local_data, verify_and_fetch_hpd_data\n",
    "from query_ll44_funding import query_and_add_financing\n",
    "from query_dob_filings import query_dob_bisweb_bin, query_dob_bisweb_bbl, query_dobnow_bin, query_dobnow_bbl, decompose_bbl, query_condo_lots_for_bbl, query_dob_by_address, pad_block, pad_lot\n",
    "from query_co_filings import query_co_filings\n",
    "from HPD_DOB_Join_On_BIN import create_separate_timelines\n",
    "from create_timeline_chart import create_timeline_chart, create_financing_charts\n",
    "\n",
    "print(\"‚úÖ All imports successful\")\n",
    "\n",
    "# Helper functions\n",
    "def _normalize_bin(bin_value) -> Optional[str]:\n",
    "    \"\"\"Normalize BIN to a clean string.\"\"\"\n",
    "    if pd.isna(bin_value):\n",
    "        return None\n",
    "    try:\n",
    "        return str(int(float(bin_value)))\n",
    "    except (TypeError, ValueError):\n",
    "        value = str(bin_value).strip()\n",
    "        return value or None\n",
    "\n",
    "def _extract_bins_from_df(df: pd.DataFrame) -> list[str]:\n",
    "    \"\"\"Extract BINs from a DataFrame and return as a list for CO searches.\"\"\"\n",
    "    candidate_cols = []\n",
    "    for col in df.columns:\n",
    "        if col.lower() in (\"bin\", \"bin_normalized\"):\n",
    "            candidate_cols.append(col)\n",
    "    if not candidate_cols:\n",
    "        raise SystemExit(f\"Could not find a BIN column in DataFrame\")\n",
    "\n",
    "    bins = []\n",
    "    for val in df[candidate_cols[0]].dropna():\n",
    "        normalized = _normalize_bin(val)\n",
    "        if normalized:\n",
    "            bins.append(normalized)\n",
    "    \n",
    "    # Remove duplicates using set, then sort\n",
    "    unique_bins = set()\n",
    "    for b in bins:\n",
    "        if b:\n",
    "            unique_bins.add(b)\n",
    "    return sorted(unique_bins)\n",
    "\n",
    "def _query_co_filings_from_bins(bin_list: list[str], output_path: Path = None) -> pd.DataFrame:\n",
    "    \"\"\"Query CO filings using a list of BINs (no file needed).\"\"\"\n",
    "    from query_co_filings import query_co_api, DOB_NOW_CO_URL, DOB_CO_URL\n",
    "    \n",
    "    # Convert BINs to integers for API query\n",
    "    bin_ints = []\n",
    "    for bin_str in bin_list:\n",
    "        if str(bin_str).isdigit():\n",
    "            bin_ints.append(int(bin_str))\n",
    "    bins = sorted(list(set(bin_ints)))\n",
    "    \n",
    "    # Query DOB NOW Certificate of Occupancy API\n",
    "    print(\"=\" * 70)\n",
    "    print(\"QUERYING DOB NOW CERTIFICATE OF OCCUPANCY\")\n",
    "    print(\"=\" * 70)\n",
    "    dob_now_co = query_co_api(DOB_NOW_CO_URL, bins, bin_column=\"bin\")\n",
    "    \n",
    "    # Query DOB Certificate Of Occupancy API\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"QUERYING DOB CERTIFICATE OF OCCUPANCY\")\n",
    "    print(\"=\" * 70)\n",
    "    dob_co = query_co_api(DOB_CO_URL, bins, bin_column=\"bin_number\")\n",
    "    \n",
    "    # Combine results\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if not dob_now_co.empty:\n",
    "        print(f\"\\nDOB NOW CO Filings: {len(dob_now_co)} records\")\n",
    "        dob_now_co['source'] = 'DOB_NOW_CO'\n",
    "        if 'bin' in dob_now_co.columns:\n",
    "            dob_now_co['bin_normalized'] = dob_now_co['bin'].astype(str)\n",
    "    \n",
    "    if not dob_co.empty:\n",
    "        print(f\"\\nDOB CO Filings: {len(dob_co)} records\")\n",
    "        dob_co['source'] = 'DOB_CO'\n",
    "        if 'bin_number' in dob_co.columns:\n",
    "            dob_co['bin_normalized'] = dob_co['bin_number'].astype(str)\n",
    "    \n",
    "    # Combine both dataframes\n",
    "    if not dob_now_co.empty and not dob_co.empty:\n",
    "        all_cols = list(set(dob_now_co.columns.tolist() + dob_co.columns.tolist()))\n",
    "        if 'bin_normalized' not in all_cols:\n",
    "            all_cols.append('bin_normalized')\n",
    "        if 'source' not in all_cols:\n",
    "            all_cols.append('source')\n",
    "        dob_now_co_aligned = dob_now_co.reindex(columns=all_cols)\n",
    "        dob_co_aligned = dob_co.reindex(columns=all_cols)\n",
    "        combined = pd.concat([dob_now_co_aligned, dob_co_aligned], ignore_index=True)\n",
    "    elif not dob_now_co.empty:\n",
    "        combined = dob_now_co.copy()\n",
    "    elif not dob_co.empty:\n",
    "        combined = dob_co.copy()\n",
    "    else:\n",
    "        print(\"\\nNo CO filings found in either API\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"\\nTotal combined records: {len(combined)}\")\n",
    "    \n",
    "    return combined\n",
    "\n",
    "print(\"‚úÖ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 1: Fetch HPD Data\n",
    "\n",
    "Load or refresh the HPD affordable housing dataset.\n",
    "\n",
    "**Options:**\n",
    "- Set `refresh_data = True` to fetch fresh data\n",
    "- Set `refresh_data = False` to use existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 Configuration\n",
    "refresh_data = False  # Set to True to fetch fresh HPD data\n",
    "hpd_output_path = \"data/raw/Affordable_Housing_Production_by_Building.csv\"  # Output path for HPD data\n",
    "refresh_hpd_projects = False  # Set to True to fetch fresh HPD projects data\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 1: FETCH HPD DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Start quality tracking\n",
    "\n",
    "# Handle HPD projects cache refresh if requested\n",
    "if refresh_hpd_projects:\n",
    "    print(\"Force refreshing HPD projects cache...\")\n",
    "    from fetch_affordable_housing_data import verify_and_fetch_hpd_projects_data\n",
    "    hpd_projects_df, hpd_projects_path = verify_and_fetch_hpd_projects_data(use_existing=False)\n",
    "    print(f\"HPD projects cache refreshed: {len(hpd_projects_df)} records\\n\")\n",
    "\n",
    "if refresh_data:\n",
    "    print(\"Fetching fresh HPD data from NYC Open Data...\")\n",
    "    hpd_df, hpd_csv = update_local_data(hpd_output_path)\n",
    "else:\n",
    "    print(\"Verifying local HPD data against API...\")\n",
    "    hpd_df, hpd_csv = verify_and_fetch_hpd_data(output_path=hpd_output_path, use_projects_cache=not refresh_hpd_projects)\n",
    "\n",
    "if not hpd_csv.exists():\n",
    "    raise SystemExit(f\"HPD dataset not found at {hpd_csv}\")\n",
    "\n",
    "# Get total units before filter\n",
    "original_count = len(hpd_df)\n",
    "original_units = hpd_df['Total Units'].sum()\n",
    "\n",
    "# Filter to New Construction only\n",
    "hpd_new_construction_df = hpd_df[hpd_df[\"Reporting Construction Type\"] == \"New Construction\"].copy()\n",
    "\n",
    "filtered_count = len(hpd_new_construction_df)\n",
    "filtered_units = hpd_new_construction_df['Total Units'].sum()\n",
    "filtered_out = original_count - filtered_count\n",
    "filtered_units_out = original_units - filtered_units\n",
    "\n",
    "print(f\"üèóÔ∏è Filtered to New Construction only:\")\n",
    "print(f\"  Original: {original_count:,} projects, {original_units:,} total units\")\n",
    "print(f\"  Filtered: {filtered_count:,} projects ({filtered_count/original_count*100:.1f}%), {filtered_units:,} total units ({filtered_units/original_units*100:.1f}%)\")\n",
    "print(f\"  Removed: {filtered_out:,} non-new construction projects ({filtered_out/original_count*100:.1f}%), {filtered_units_out:,} units filtered out ({filtered_units_out/original_units*100:.1f}%)\")\n",
    "\n",
    "print(f\"‚úÖ Step 1 complete: {len(hpd_new_construction_df):,} records loaded\")\n",
    "print(f\"üìÅ Data location: {hpd_csv}\")\n",
    "\n",
    "# Display the dataframe\n",
    "print(\"\\nüîç HPD Dataset Overview (New Construction only):\")\n",
    "print(f\"Shape: {hpd_new_construction_df.shape}\")\n",
    "print(\"\\nColumns:\")\n",
    "for col in hpd_new_construction_df.columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(\"\\nüìä Sample Data:\")\n",
    "display(hpd_new_construction_df.head())\n",
    "print(\"\\nüìà Basic Statistics:\")\n",
    "display(hpd_new_construction_df.describe(include=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique counts are there by project id as primary key per program group,\n",
    "# and show total units in parentheticals (but NOT for the unique project counts).\n",
    "\n",
    "# Compute total units per Program Group (all rows)\n",
    "units_per_group = hpd_new_construction_df.groupby('Program Group')['Total Units'].sum()\n",
    "\n",
    "print(\"Program Group counts (raw rows) (total units in parentheses):\")\n",
    "raw_row_counts = hpd_new_construction_df['Program Group'].value_counts()\n",
    "for group, count in raw_row_counts.items():\n",
    "    units = units_per_group.get(group, 0)\n",
    "    print(f\"{group}: {count} rows ({units} units)\")\n",
    "print()\n",
    "\n",
    "# Group by Program Group, count unique Project IDs\n",
    "unique_proj_counts = hpd_new_construction_df.groupby('Program Group')['Project ID'].nunique().sort_values(ascending=False)\n",
    "unique_proj_ids = (\n",
    "    hpd_new_construction_df\n",
    "    .groupby('Program Group')\n",
    "    .apply(lambda df: df['Project ID'].unique())\n",
    ")\n",
    "\n",
    "print(\"Program Group counts (unique Project ID as primary key):\")\n",
    "for group, count in unique_proj_counts.items():\n",
    "    print(f\"{group}: {count} projects\")\n",
    "print()\n",
    "\n",
    "print(\"\\nTax Abatement by Program Group (based on unique Project ID):\")\n",
    "if 'Planned Tax Benefit' in hpd_new_construction_df.columns:\n",
    "    # For this, deduplicate by Project ID first\n",
    "    unique_project_rows = hpd_new_construction_df.drop_duplicates(subset=['Project ID'])\n",
    "    tax_abate_ct = (\n",
    "        unique_project_rows\n",
    "        .groupby('Program Group')['Planned Tax Benefit']\n",
    "        .value_counts(dropna=False)\n",
    "        .unstack(fill_value=0)\n",
    "        .sort_index(axis=1)\n",
    "    )\n",
    "    # Also display total units per Program Group in this table, if desired\n",
    "    units_per_group_project = unique_project_rows.groupby('Program Group')['Total Units'].sum()\n",
    "    print(\"Total units (unique Project ID per Program Group):\")\n",
    "    display(units_per_group_project)\n",
    "    display(tax_abate_ct)\n",
    "else:\n",
    "    print(\"Column 'Planned Tax Benefit' not found in dataset.\")\n",
    "\n",
    "# Make a version of this with unit count by program and tax benefit\n",
    "if 'Planned Tax Benefit' in unique_project_rows.columns and 'Program Group' in unique_project_rows.columns:\n",
    "    units_pivot = (\n",
    "        unique_project_rows\n",
    "        .groupby(['Program Group', 'Planned Tax Benefit'])['Total Units']\n",
    "        .sum()\n",
    "        .unstack(fill_value=0)\n",
    "        .sort_index(axis=1)\n",
    "    )\n",
    "    print(\"Total units by Program Group and Planned Tax Benefit (unique Project ID only):\")\n",
    "    display(units_pivot)\n",
    "else:\n",
    "    print(\"Required columns not found for unit pivot table.\")\n",
    "\n",
    "# Calculate average units per year by Program Group and Planned Tax Benefit\n",
    "\n",
    "if 'Project Start Date' in unique_project_rows.columns and 'Total Units' in unique_project_rows.columns:\n",
    "    # Extract year from 'Project Start Date'\n",
    "    unique_project_rows = unique_project_rows.copy()\n",
    "    unique_project_rows['Project Year'] = pd.to_datetime(unique_project_rows['Project Start Date'], errors='coerce').dt.year\n",
    "\n",
    "    avg_units_per_year = (\n",
    "        unique_project_rows\n",
    "        .groupby(['Program Group', 'Planned Tax Benefit', 'Project Year'])['Total Units']\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Now calculate the average units per year by program group and tax abatement\n",
    "    avg_units_table = (\n",
    "        avg_units_per_year\n",
    "        .groupby(['Program Group', 'Planned Tax Benefit'])['Total Units']\n",
    "        .mean()\n",
    "        .unstack(fill_value=0)\n",
    "        .sort_index(axis=1)\n",
    "    )\n",
    "    print(\"Average units per year by Program Group and Planned Tax Benefit (unique Project ID only):\")\n",
    "    display(avg_units_table)\n",
    "else:\n",
    "    print(\"Required columns not found for average units per year table.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We'll use the full raw HPD data, because we want all programs, not just Multifamily Finance Program\n",
    "if 'Project Start Date' in hpd_new_construction_df.columns and 'Total Units' in hpd_new_construction_df.columns:\n",
    "    hpd_bar_df = hpd_new_construction_df.copy()\n",
    "    hpd_bar_df['Project Year'] = pd.to_datetime(hpd_bar_df['Project Start Date'], errors='coerce').dt.year\n",
    "\n",
    "    # Only focus on desired groups\n",
    "    programs_of_interest = ['Multifamily Finance Program', 'Multifamily Incentives Program']\n",
    "    mask = hpd_bar_df['Program Group'].isin(programs_of_interest)\n",
    "    hpd_bar_df = hpd_bar_df[mask & hpd_bar_df['Project Year'].notna()]\n",
    "\n",
    "    # Fill NAs in Planned Tax Benefit with \"None\"\n",
    "    hpd_bar_df['Planned Tax Benefit'] = hpd_bar_df['Planned Tax Benefit'].fillna('None')\n",
    "\n",
    "    # Prepare for grouped bar with stack\n",
    "    # Pivot: rows = Project Year, columns = (Program Group, Planned Tax Benefit), values = sum of units\n",
    "    pivot = (\n",
    "        hpd_bar_df\n",
    "        .groupby(['Project Year', 'Program Group', 'Planned Tax Benefit'])['Total Units']\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Ensure proper order of years and programs\n",
    "    years = sorted(pivot['Project Year'].dropna().unique())\n",
    "    tax_benefits = sorted(pivot['Planned Tax Benefit'].unique())\n",
    "    # Keep consistent order for bars\n",
    "    program_order = ['Multifamily Finance Program', 'Multifamily Incentives Program']\n",
    "\n",
    "    # Prepare data structure: for each year, for each program, get breakdown by tax benefit\n",
    "    bar_data = {}\n",
    "    for year in years:\n",
    "        bar_data[year] = {}\n",
    "        for prog in program_order:\n",
    "            mask = (pivot['Project Year'] == year) & (pivot['Program Group'] == prog)\n",
    "            year_prog_data = pivot[mask].set_index('Planned Tax Benefit')['Total Units'].reindex(tax_benefits, fill_value=0)\n",
    "            bar_data[year][prog] = year_prog_data.values\n",
    "\n",
    "    # Number of bars per group (2 programs), group by year, stacked by tax benefit\n",
    "    x = range(len(years))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    # Colors for planned tax benefits\n",
    "    import matplotlib.cm as cm\n",
    "    color_map = cm.get_cmap('tab20', len(tax_benefits))\n",
    "    colors = []\n",
    "    for i in range(len(tax_benefits)):\n",
    "        colors.append(color_map(i))\n",
    "\n",
    "    bottoms_p1 = [0] * len(years)\n",
    "    bottoms_p2 = [0] * len(years)\n",
    "\n",
    "    # For each tax benefit, draw the stack pieces for both programs\n",
    "    legend_handles = []\n",
    "    for idx, tax in enumerate(tax_benefits):\n",
    "        values_p1 = []\n",
    "        for year in years:\n",
    "            values_p1.append(bar_data[year][program_order[0]][idx])\n",
    "        values_p2 = []\n",
    "        for year in years:\n",
    "            values_p2.append(bar_data[year][program_order[1]][idx])\n",
    "\n",
    "        x_positions_p1 = []\n",
    "        for i in x:\n",
    "            x_positions_p1.append(i - width/2)\n",
    "        x_positions_p2 = []\n",
    "        for i in x:\n",
    "            x_positions_p2.append(i + width/2)\n",
    "        \n",
    "        legend_labels = []\n",
    "        for h in legend_handles:\n",
    "            legend_labels.append(h.get_label())\n",
    "        \n",
    "        bar1 = ax.bar(\n",
    "            x_positions_p1, values_p1, width,\n",
    "            bottom=bottoms_p1, color=colors[idx],\n",
    "            label=tax if (tax not in legend_labels) else None,\n",
    "            edgecolor='black', hatch='////'\n",
    "        )\n",
    "        bar2 = ax.bar(\n",
    "            x_positions_p2, values_p2, width,\n",
    "            bottom=bottoms_p2, color=colors[idx],\n",
    "            label=None,\n",
    "            edgecolor='black'\n",
    "        )\n",
    "\n",
    "        legend_labels = []\n",
    "        for h in legend_handles:\n",
    "            legend_labels.append(h.get_label())\n",
    "        if tax not in legend_labels:\n",
    "            legend_handles.append(bar1)\n",
    "\n",
    "        new_bottoms_p1 = []\n",
    "        for b, v in zip(bottoms_p1, values_p1):\n",
    "            new_bottoms_p1.append(b + v)\n",
    "        bottoms_p1 = new_bottoms_p1\n",
    "        \n",
    "        new_bottoms_p2 = []\n",
    "        for b, v in zip(bottoms_p2, values_p2):\n",
    "            new_bottoms_p2.append(b + v)\n",
    "        bottoms_p2 = new_bottoms_p2\n",
    "\n",
    "    # Add year labels\n",
    "    ax.set_xticks(x)\n",
    "    year_labels = []\n",
    "    for y in years:\n",
    "        year_labels.append(str(int(y)))\n",
    "    ax.set_xticklabels(year_labels, rotation=45)\n",
    "    ax.set_xlabel(\"Project Start Year\")\n",
    "    ax.set_ylabel(\"Total Units Financed\")\n",
    "    ax.set_title(\"Units Financed by Year: Multifamily Finance and Incentives Programs\\nColored by Planned Tax Benefit\")\n",
    "\n",
    "    # Custom legend for program groups\n",
    "    import matplotlib.patches as mpatches\n",
    "    progs = [\n",
    "        mpatches.Patch(color='gray', label='Multifamily Finance Program', ec='black', hatch='////'),\n",
    "        mpatches.Patch(color='gray', label='Multifamily Incentives Program', ec='black')\n",
    "    ]\n",
    "    # Only add one legend for planned tax benefit\n",
    "    handles_tax = []\n",
    "    for i in range(len(tax_benefits)):\n",
    "        handles_tax.append(plt.Rectangle((0,0),1,1, color=colors[i], edgecolor='black', label=f\"{tax_benefits[i]}\"))\n",
    "    legend1 = ax.legend(handles=handles_tax, title=\"Planned Tax Benefit\", loc='upper right')\n",
    "    ax.add_artist(legend1)\n",
    "    # Add manual tick legend for program bars\n",
    "    bar_locs = [x[0] - width/2, x[0] + width/2]\n",
    "    ax.bar(bar_locs[0], 0, width, color='white', hatch='////', ec='black', label='Multifamily Finance Program')\n",
    "    ax.bar(bar_locs[1], 0, width, color='white', ec='black', label='Multifamily Incentives Program')\n",
    "    ax.legend(\n",
    "        handles=[\n",
    "            plt.Rectangle((0,0),1,1, facecolor='white', hatch='////', edgecolor='black', label='Multifamily Finance Program'),\n",
    "            plt.Rectangle((0,0),1,1, facecolor='white', edgecolor='black', label='Multifamily Incentives Program')\n",
    "        ], title=\"Program Group\", loc='upper left'\n",
    "    )\n",
    "\n",
    "    ax.grid(True, which='major', axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Required columns ('Project Start Date', 'Total Units') not found in HPD Data.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count and sample: Planned Tax Benefit '421a' and Project Start Date in 2025\n",
    "if \"Planned Tax Benefit\" in hpd_new_construction_df.columns and \"Project Start Date\" in hpd_new_construction_df.columns:\n",
    "    # Filter for 421a and 2025 start year\n",
    "    mask_421a_2025 = (\n",
    "        (hpd_new_construction_df[\"Planned Tax Benefit\"] == \"421a\") &\n",
    "        (hpd_new_construction_df[\"Project Start Date\"].astype(str).str.startswith(\"2025\"))\n",
    "    )\n",
    "    hpd_421a_2025_df = hpd_new_construction_df[mask_421a_2025]\n",
    "\n",
    "    # Count unique projects (by Project ID), and total units\n",
    "    total_projects = hpd_421a_2025_df[\"Project ID\"].nunique() if \"Project ID\" in hpd_421a_2025_df.columns else len(hpd_421a_2025_df)\n",
    "    total_units = hpd_421a_2025_df[\"Total Units\"].sum() if \"Total Units\" in hpd_421a_2025_df.columns else \"N/A\"\n",
    "\n",
    "    print(f\"Total projects with Planned Tax Benefit '421a' and 2025 Start Date: {total_projects:,}\")\n",
    "    print(f\"Total units in these projects: {total_units:,}\")\n",
    "\n",
    "    # Show up to 5 sample rows\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    print(\"\\nSample 421a Planned Tax Benefit projects with Project Start Date in 2025:\")\n",
    "    display(hpd_421a_2025_df)\n",
    "    pd.reset_option('display.max_columns')\n",
    "else:\n",
    "    print(\"One or both of the columns 'Planned Tax Benefit' or 'Project Start Date' not found in HPD DataFrame.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to Multifamily Finance Program (already filtered to New Construction in Step 1)\n",
    "original_count = len(hpd_new_construction_df)\n",
    "print(f\"Using HPD data from Step 1: {original_count:,} total buildings (New Construction)\")\n",
    "\n",
    "# Apply filters: Multifamily Finance Program (already filtered to New Construction in Step 1)\n",
    "hpd_multifamily_finance_new_construction_df = hpd_new_construction_df[\n",
    "    hpd_new_construction_df[\"Program Group\"] == \"Multifamily Finance Program\"\n",
    "].copy()\n",
    "filtered_count = len(hpd_multifamily_finance_new_construction_df)\n",
    "\n",
    "print(f\"üèóÔ∏è Filtered to Multifamily Finance Program:\")\n",
    "print(f\"  Original: {original_count:,} buildings (New Construction)\")\n",
    "print(f\"  Filtered: {filtered_count:,} buildings ({filtered_count/original_count*100:.1f}%)\")\n",
    "print(f\"üìÅ Created critical DataFrame in memory: {filtered_count:,} Multifamily Finance Program (New Construction) buildings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Step 3: Query DOB Filings\n",
    "\n",
    "Search for DOB New Building filings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3A: BIN/BBL Prep and Filtering\n",
    "\n",
    "# Use hpd_multifamily_finance_new_construction_df from Step 2.5 (in memory)\n",
    "print(f\"Using filtered dataset from Step 2.5: {len(hpd_multifamily_finance_new_construction_df):,} Multifamily Finance Program (New Construction) buildings\")\n",
    "\n",
    "# Extract BINs and BBLs from the filtered data\n",
    "bins = []\n",
    "bin_counts = hpd_multifamily_finance_new_construction_df['BIN'].value_counts()\n",
    "unique_bins = bin_counts[bin_counts == 1].index.tolist()\n",
    "# Extract BBLs properly using decompose_bbl function\n",
    "from query_dob_filings import decompose_bbl\n",
    "\n",
    "bbls = []\n",
    "for idx, row in hpd_multifamily_finance_new_construction_df.iterrows():\n",
    "    if pd.notna(row.get(\"BBL\")):\n",
    "        bbl_result = decompose_bbl(str(row[\"BBL\"]))\n",
    "        if bbl_result and len(bbl_result) >= 3:\n",
    "            borough, block, lot = bbl_result\n",
    "            bbls.append((borough, block, lot))\n",
    "\n",
    "\n",
    "# Filter out bad/placeholder BINs (e.g., 1000000, 2000000, 3000000, 4000000, 5000000)\n",
    "# These are placeholder values that don't exist in DOB\n",
    "def is_bad_bin(bin_str):\n",
    "    \"\"\"Check if BIN is a placeholder/bad value.\"\"\"\n",
    "    if not bin_str or pd.isna(bin_str) or str(bin_str).lower() == 'nan':\n",
    "        return True\n",
    "    bin_str_clean = str(bin_str).strip()\n",
    "    # Check for pattern: [1-5]000000 (borough placeholder BINs)\n",
    "    if bin_str_clean in ['1000000', '2000000', '3000000', '4000000', '5000000']:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "if 'BIN' in hpd_multifamily_finance_new_construction_df.columns:\n",
    "    bins = []\n",
    "for b in hpd_multifamily_finance_new_construction_df['BIN'].dropna():\n",
    "        b_str = str(b)\n",
    "        if b_str != 'nan':\n",
    "            b_clean = b_str.replace('.0', '')\n",
    "            if not is_bad_bin(b_clean) and b_clean in unique_bins:\n",
    "                bins.append(b_clean)\n",
    "\n",
    "if 'BBL' in hpd_multifamily_finance_new_construction_df.columns:\n",
    "    bbl_col = hpd_multifamily_finance_new_construction_df['BBL'].astype(str).str.zfill(10)\n",
    "    bbls = []\n",
    "    for bbl_val in bbl_col:\n",
    "        if len(bbl_val) == 10:\n",
    "            bbl_tuple = (\n",
    "                bbl_val[0],                     # borough code (as string)\n",
    "                bbl_val[1:6],                   # block (padded 5 chars)\n",
    "                bbl_val[6:]                     # lot   (padded 4 chars)\n",
    "            )\n",
    "            bbls.append(bbl_tuple)\n",
    "\n",
    "print(f\"\\nüìã Prepared {len(bins)} BINs and {len(bbls)} BBLs for DOB queries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. BISWEB BIN for all buildings\n",
    "\n",
    "print(\"BISWEB BIN QUERY (ALL BUILDINGS)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"‚ñ∂Ô∏è Querying BISWEB BIN for {len(bins)} buildings...\")\n",
    "dob_bisweb_bin_df = query_dob_bisweb_bin(bins)\n",
    "bisweb_bin_matches = set()\n",
    "if not dob_bisweb_bin_df.empty and \"bin__\" in dob_bisweb_bin_df.columns:\n",
    "    bisweb_bin_matches = set(dob_bisweb_bin_df[\"bin__\"].dropna().astype(str).unique())\n",
    "bisweb_bin_unmatched = []\n",
    "for b in bins:\n",
    "    if b not in bisweb_bin_matches:\n",
    "        bisweb_bin_unmatched.append(b)\n",
    "print(f\"BISWEB BIN: {len(bisweb_bin_matches)} matches, {len(bisweb_bin_unmatched)} need BBL fallback\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Preview BISWEB BIN results\n",
    "if not dob_bisweb_bin_df.empty:\n",
    "    print(\"\\nüìä BISWEB BIN sample:\")\n",
    "    display(dob_bisweb_bin_df.head())\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No BISWEB BIN results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. DOB NOW BIN for all buildings\n",
    "print(\"=\" * 70)\n",
    "print(\"DOB NOW BIN QUERY (ALL BUILDINGS)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"‚ñ∂Ô∏è Querying DOB NOW BIN for {len(bins)} buildings...\")\n",
    "dob_now_bin_df = query_dobnow_bin(bins)\n",
    "dobnow_bin_matches = set()\n",
    "if not dob_now_bin_df.empty:\n",
    "    dobnow_bin_matches = set(dob_now_bin_df[\"bin\"].dropna().astype(str).unique())\n",
    "    print(\"üìä DOB NOW BIN sample:\")\n",
    "    display(dob_now_bin_df.head())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No DOB NOW BIN results\")\n",
    "\n",
    "print(f\"DOB NOW BIN: {len(dobnow_bin_matches)} unique BINs and {len(dob_now_bin_df)} total job records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. DETERMINE UNMATCHED PROJECTS\n",
    "\n",
    "# Combine matched BINs from both API queries\n",
    "all_matched_bins = bisweb_bin_matches.union(dobnow_bin_matches)\n",
    "\n",
    "# Find projects with BINs that failed both BISWEB and DOB NOW queries\n",
    "# Create a DataFrame of projects whose BINs were not matched by either BISWEB or DOB NOW queries.\n",
    "# This uses .isin(all_matched_bins) to check which projects' BINs are missing from the set of matched BINs,\n",
    "# and selects only those projects to proceed to BBL fallback lookup.\n",
    "unmatched_projects_df = hpd_multifamily_finance_new_construction_df[\n",
    "    ~hpd_multifamily_finance_new_construction_df[\"BIN\"]\n",
    "        .astype(str)\n",
    "        .str.replace(\".0\", \"\")\n",
    "        .isin(all_matched_bins)\n",
    "].copy()\n",
    "\n",
    "print(f\"BIN QUERY RESULTS SUMMARY\")\n",
    "print(f\"=\" * 50)\n",
    "print(f\"Total projects in dataset: {len(hpd_multifamily_finance_new_construction_df)}\")\n",
    "matched_projects = hpd_multifamily_finance_new_construction_df[hpd_multifamily_finance_new_construction_df[\"BIN\"].astype(str).str.replace(\".0\", \"\").isin(all_matched_bins)]\n",
    "print(f\"Unique BINs found in BISWEB/DOB NOW APIs: {len(all_matched_bins)}\")\n",
    "print(f\"Projects covered by those BINs: {len(matched_projects)} (some BINs cover multiple projects)\")\n",
    "\n",
    "# Analyze BIN sharing\n",
    "bin_counts = hpd_multifamily_finance_new_construction_df[\"BIN\"].value_counts()\n",
    "bins_used_multiple_times = len(bin_counts[bin_counts > 1])\n",
    "extra_projects_from_sharing = bin_counts[bin_counts > 1].sum() - bins_used_multiple_times\n",
    "print(f\"Projects needing fallback queries: {len(unmatched_projects_df)}\")\n",
    "print(f\"BIN matching success rate: {len(matched_projects)/len(hpd_multifamily_finance_new_construction_df)*100:.1f}% of projects covered\")\n",
    "\n",
    "# Sanity check\n",
    "total_accounted_for = len(matched_projects) + len(unmatched_projects_df)\n",
    "print(f\"Sanity check: {len(matched_projects)} + {len(unmatched_projects_df)} = {total_accounted_for} (should equal {len(hpd_multifamily_finance_new_construction_df)})\")\n",
    "\n",
    "if not unmatched_projects_df.empty:\n",
    "    print(f\"Unmatched projects will proceed to fallback queries (BBL ‚Üí Condo ‚Üí Address)\")\n",
    "else:\n",
    "    print(f\"All projects successfully matched via BIN queries! No fallbacks needed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpd_multifamily_finance_new_construction_df[\n",
    "    (hpd_multifamily_finance_new_construction_df[\"BIN\"].duplicated(keep=False)) & \n",
    "    (~hpd_multifamily_finance_new_construction_df[\"BIN\"].astype(str).apply(is_bad_bin))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BISWEB BBL FALLBACK\n",
    "if not unmatched_projects_df.empty:\n",
    "    print(\"\" + \"=\" * 70)\n",
    "    print(\"BISWEB BBL FALLBACK\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Extract BBLs from unmatched projects\n",
    "    bbl_tuples = []\n",
    "    for _, row in unmatched_projects_df.iterrows():\n",
    "        if pd.notna(row.get(\"BBL\")):\n",
    "            bbl_result = decompose_bbl(str(row[\"BBL\"]))\n",
    "            if bbl_result and len(bbl_result) >= 3:\n",
    "                bbl_tuples.append(bbl_result)\n",
    "    \n",
    "    # Deduplicate BBLs\n",
    "    bbl_tuples = list(set(bbl_tuples))\n",
    "    print(f\"Extracted {len(bbl_tuples)} unique BBLs from unmatched projects\")\n",
    "    \n",
    "    # Query BISWEB BBL API\n",
    "    print(f\"‚ñ∂Ô∏è Querying BISWEB BBL for {len(bbl_tuples)} BBLs...\")\n",
    "    dob_bisweb_bbl_df = query_dob_bisweb_bbl(bbl_tuples)\n",
    "    \n",
    "    # DOB NOW BBL fallback\n",
    "    print(\"\" + \"=\" * 70)\n",
    "    print(\"DOB NOW BBL FALLBACK\")\n",
    "    print(\"=\" * 70)\n",
    "    dob_now_bbl_df = query_dobnow_bbl(bbl_tuples)\n",
    "else:\n",
    "    # No unmatched projects, initialize empty dataframes\n",
    "    dob_bisweb_bbl_df = pd.DataFrame()\n",
    "    dob_now_bbl_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total DOB records: 3394\n",
      "Projects matched on BIN: 257\n",
      "Projects matched on BBL (fallback): 93\n",
      "\n",
      "Total Multifamily Finance Program new construction projects: 382\n",
      "Projects with DOB matches: 350\n",
      "Number of these with NO DOB row in any table: 32\n",
      "\n",
      "Sample matched on BIN: ['60012', '44225', '58671']\n",
      "Sample matched on BBL: ['73229', '64114', '74805']\n",
      "Sample unmatched: ['58621', '63772', '66212']\n",
      "\n",
      "=== DEBUG: Sample unmatched project ===\n",
      "Project ID: 58621\n",
      "Number of buildings in project: 1\n",
      "BINs in project: ['4000000']\n",
      "BBLs in project: ['4097937502']\n",
      "BINs found in DOB data: None\n",
      "BBLs found in DOB data: None\n",
      "\n",
      "Head of unmatched Multifamily Finance Program new construction projects:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/lk1n_dqn4gj0n_tsqkvpx_cw0000gn/T/ipykernel_92284/2548092176.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_dob_with_normalized_bbl_df['bbl_reconstructed'] = combined_dob_with_normalized_bbl_df.apply(reconstruct_bbl, axis=1)\n",
      "/var/folders/cy/lk1n_dqn4gj0n_tsqkvpx_cw0000gn/T/ipykernel_92284/2548092176.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_dob_with_normalized_bbl_df['bbl_normalized'] = combined_dob_with_normalized_bbl_df['bbl'].apply(lambda x: str(int(float(x))).zfill(10) if pd.notna(x) else None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project ID</th>\n",
       "      <th>Project Name</th>\n",
       "      <th>Project Start Date</th>\n",
       "      <th>Building ID</th>\n",
       "      <th>Number</th>\n",
       "      <th>Street</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>BBL</th>\n",
       "      <th>BIN</th>\n",
       "      <th>...</th>\n",
       "      <th>6-BR+ Units</th>\n",
       "      <th>Unknown-BR Units</th>\n",
       "      <th>Counted Rental Units</th>\n",
       "      <th>Counted Homeownership Units</th>\n",
       "      <th>All Counted Units</th>\n",
       "      <th>Total Units</th>\n",
       "      <th>Program Group</th>\n",
       "      <th>Project Completion Date</th>\n",
       "      <th>Extended Affordability Status</th>\n",
       "      <th>Planned Tax Benefit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>44348</td>\n",
       "      <td>Crossroads Plaza- Rental Low</td>\n",
       "      <td>2014-01-28T00:00:00.000</td>\n",
       "      <td>950310</td>\n",
       "      <td>501</td>\n",
       "      <td>SOUTHERN BOULEVARD</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>10455</td>\n",
       "      <td>2025827502</td>\n",
       "      <td>2128607</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.0</td>\n",
       "      <td>136</td>\n",
       "      <td>Multifamily Finance Program</td>\n",
       "      <td>2017-04-12T00:00:00.000</td>\n",
       "      <td>No</td>\n",
       "      <td>420c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>44409</td>\n",
       "      <td>Crotona Terrace II</td>\n",
       "      <td>2015-06-25T00:00:00.000</td>\n",
       "      <td>927022</td>\n",
       "      <td>1825</td>\n",
       "      <td>BOSTON ROAD</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>10460</td>\n",
       "      <td>2029847503</td>\n",
       "      <td>2124684</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108</td>\n",
       "      <td>Multifamily Finance Program</td>\n",
       "      <td>2018-01-12T00:00:00.000</td>\n",
       "      <td>No</td>\n",
       "      <td>420c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>50104</td>\n",
       "      <td>Crotona Terrace I aka 1825 Boston Road</td>\n",
       "      <td>2014-10-02T00:00:00.000</td>\n",
       "      <td>927022</td>\n",
       "      <td>1825</td>\n",
       "      <td>BOSTON ROAD</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>10460</td>\n",
       "      <td>2029847503</td>\n",
       "      <td>2124684</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80</td>\n",
       "      <td>Multifamily Finance Program</td>\n",
       "      <td>2016-10-28T00:00:00.000</td>\n",
       "      <td>No</td>\n",
       "      <td>421a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>50497</td>\n",
       "      <td>655 Morris Avenue</td>\n",
       "      <td>2014-06-26T00:00:00.000</td>\n",
       "      <td>806842</td>\n",
       "      <td>635</td>\n",
       "      <td>MORRIS AVENUE</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>10451</td>\n",
       "      <td>2024410001</td>\n",
       "      <td>2002441</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176.0</td>\n",
       "      <td>176</td>\n",
       "      <td>Multifamily Finance Program</td>\n",
       "      <td>2016-12-01T00:00:00.000</td>\n",
       "      <td>No</td>\n",
       "      <td>420c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>52610</td>\n",
       "      <td>Crossroads Plaza I</td>\n",
       "      <td>2014-12-19T00:00:00.000</td>\n",
       "      <td>950310</td>\n",
       "      <td>501</td>\n",
       "      <td>SOUTHERN BOULEVARD</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>10455</td>\n",
       "      <td>2025827502</td>\n",
       "      <td>2128607</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163.0</td>\n",
       "      <td>163</td>\n",
       "      <td>Multifamily Finance Program</td>\n",
       "      <td>2018-08-16T00:00:00.000</td>\n",
       "      <td>No</td>\n",
       "      <td>421a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>58621</td>\n",
       "      <td>TREE OF LIFE</td>\n",
       "      <td>2017-05-24T00:00:00.000</td>\n",
       "      <td>972781</td>\n",
       "      <td>89-48</td>\n",
       "      <td>164 STREET</td>\n",
       "      <td>Queens</td>\n",
       "      <td>11432</td>\n",
       "      <td>4097937502</td>\n",
       "      <td>4000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.0</td>\n",
       "      <td>174</td>\n",
       "      <td>Multifamily Finance Program</td>\n",
       "      <td>2024-05-23T00:00:00.000</td>\n",
       "      <td>No</td>\n",
       "      <td>Article XI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>58666</td>\n",
       "      <td>BRKG GND. AAPCI. 3 LIVONIA AVE. EDWIN'S PLACE</td>\n",
       "      <td>2018-06-28T00:00:00.000</td>\n",
       "      <td>968251</td>\n",
       "      <td>278</td>\n",
       "      <td>GRAFTON STREET</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11212</td>\n",
       "      <td>3035660006</td>\n",
       "      <td>3000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.0</td>\n",
       "      <td>126</td>\n",
       "      <td>Multifamily Finance Program</td>\n",
       "      <td>2020-09-22T00:00:00.000</td>\n",
       "      <td>No</td>\n",
       "      <td>420c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>58954</td>\n",
       "      <td>94-02 148th Street</td>\n",
       "      <td>2016-06-28T00:00:00.000</td>\n",
       "      <td>968125</td>\n",
       "      <td>94-02</td>\n",
       "      <td>148 STREET</td>\n",
       "      <td>Queens</td>\n",
       "      <td>11435</td>\n",
       "      <td>4099997501</td>\n",
       "      <td>4000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>380.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>380.0</td>\n",
       "      <td>380</td>\n",
       "      <td>Multifamily Finance Program</td>\n",
       "      <td>2018-09-24T00:00:00.000</td>\n",
       "      <td>No</td>\n",
       "      <td>Article XI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>61271</td>\n",
       "      <td>DOE. 555 NEREID AVE. MULLER</td>\n",
       "      <td>2019-03-28T00:00:00.000</td>\n",
       "      <td>99387</td>\n",
       "      <td>555</td>\n",
       "      <td>NEREID AVENUE</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>10470</td>\n",
       "      <td>2050650001</td>\n",
       "      <td>2070559</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Multifamily Finance Program</td>\n",
       "      <td>2021-07-09T00:00:00.000</td>\n",
       "      <td>No</td>\n",
       "      <td>420c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>61290</td>\n",
       "      <td>ICL. 50 NEVINS STREET</td>\n",
       "      <td>2019-03-26T00:00:00.000</td>\n",
       "      <td>342273</td>\n",
       "      <td>50</td>\n",
       "      <td>NEVINS STREET</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11217</td>\n",
       "      <td>3001727501</td>\n",
       "      <td>3000556</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129</td>\n",
       "      <td>Multifamily Finance Program</td>\n",
       "      <td>2022-04-13T00:00:00.000</td>\n",
       "      <td>No</td>\n",
       "      <td>420c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Project ID                                   Project Name  \\\n",
       "71        44348                   Crossroads Plaza- Rental Low   \n",
       "77        44409                             Crotona Terrace II   \n",
       "271       50104         Crotona Terrace I aka 1825 Boston Road   \n",
       "455       50497                              655 Morris Avenue   \n",
       "629       52610                             Crossroads Plaza I   \n",
       "1770      58621                                   TREE OF LIFE   \n",
       "1788      58666  BRKG GND. AAPCI. 3 LIVONIA AVE. EDWIN'S PLACE   \n",
       "1961      58954                             94-02 148th Street   \n",
       "2360      61271                    DOE. 555 NEREID AVE. MULLER   \n",
       "2361      61290                          ICL. 50 NEVINS STREET   \n",
       "\n",
       "           Project Start Date Building ID Number              Street  \\\n",
       "71    2014-01-28T00:00:00.000      950310    501  SOUTHERN BOULEVARD   \n",
       "77    2015-06-25T00:00:00.000      927022   1825         BOSTON ROAD   \n",
       "271   2014-10-02T00:00:00.000      927022   1825         BOSTON ROAD   \n",
       "455   2014-06-26T00:00:00.000      806842    635       MORRIS AVENUE   \n",
       "629   2014-12-19T00:00:00.000      950310    501  SOUTHERN BOULEVARD   \n",
       "1770  2017-05-24T00:00:00.000      972781  89-48          164 STREET   \n",
       "1788  2018-06-28T00:00:00.000      968251    278      GRAFTON STREET   \n",
       "1961  2016-06-28T00:00:00.000      968125  94-02          148 STREET   \n",
       "2360  2019-03-28T00:00:00.000       99387    555       NEREID AVENUE   \n",
       "2361  2019-03-26T00:00:00.000      342273     50       NEVINS STREET   \n",
       "\n",
       "       Borough Postcode         BBL      BIN  ... 6-BR+ Units  \\\n",
       "71       Bronx    10455  2025827502  2128607  ...         NaN   \n",
       "77       Bronx    10460  2029847503  2124684  ...         NaN   \n",
       "271      Bronx    10460  2029847503  2124684  ...         NaN   \n",
       "455      Bronx    10451  2024410001  2002441  ...         NaN   \n",
       "629      Bronx    10455  2025827502  2128607  ...         NaN   \n",
       "1770    Queens    11432  4097937502  4000000  ...         NaN   \n",
       "1788  Brooklyn    11212  3035660006  3000000  ...         NaN   \n",
       "1961    Queens    11435  4099997501  4000000  ...         NaN   \n",
       "2360     Bronx    10470  2050650001  2070559  ...         NaN   \n",
       "2361  Brooklyn    11217  3001727501  3000556  ...         NaN   \n",
       "\n",
       "     Unknown-BR Units Counted Rental Units Counted Homeownership Units  \\\n",
       "71                NaN                136.0                         NaN   \n",
       "77                NaN                108.0                         NaN   \n",
       "271               NaN                 80.0                         NaN   \n",
       "455               NaN                176.0                         NaN   \n",
       "629               NaN                163.0                         NaN   \n",
       "1770              NaN                174.0                         NaN   \n",
       "1788              NaN                126.0                         NaN   \n",
       "1961              NaN                380.0                         NaN   \n",
       "2360              NaN                 90.0                         NaN   \n",
       "2361              NaN                129.0                         NaN   \n",
       "\n",
       "      All Counted Units  Total Units                Program Group  \\\n",
       "71                136.0          136  Multifamily Finance Program   \n",
       "77                108.0          108  Multifamily Finance Program   \n",
       "271                80.0           80  Multifamily Finance Program   \n",
       "455               176.0          176  Multifamily Finance Program   \n",
       "629               163.0          163  Multifamily Finance Program   \n",
       "1770              174.0          174  Multifamily Finance Program   \n",
       "1788              126.0          126  Multifamily Finance Program   \n",
       "1961              380.0          380  Multifamily Finance Program   \n",
       "2360               90.0           90  Multifamily Finance Program   \n",
       "2361              129.0          129  Multifamily Finance Program   \n",
       "\n",
       "      Project Completion Date Extended Affordability Status  \\\n",
       "71    2017-04-12T00:00:00.000                            No   \n",
       "77    2018-01-12T00:00:00.000                            No   \n",
       "271   2016-10-28T00:00:00.000                            No   \n",
       "455   2016-12-01T00:00:00.000                            No   \n",
       "629   2018-08-16T00:00:00.000                            No   \n",
       "1770  2024-05-23T00:00:00.000                            No   \n",
       "1788  2020-09-22T00:00:00.000                            No   \n",
       "1961  2018-09-24T00:00:00.000                            No   \n",
       "2360  2021-07-09T00:00:00.000                            No   \n",
       "2361  2022-04-13T00:00:00.000                            No   \n",
       "\n",
       "     Planned Tax Benefit  \n",
       "71                  420c  \n",
       "77                  420c  \n",
       "271                 421a  \n",
       "455                 420c  \n",
       "629                 421a  \n",
       "1770          Article XI  \n",
       "1788                420c  \n",
       "1961          Article XI  \n",
       "2360                420c  \n",
       "2361                420c  \n",
       "\n",
       "[10 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For Multifamily Finance Program (MFP) new construction projects, find those with no DOB match in any table.\n",
    "\n",
    "# Use hpd_multifamily_finance_new_construction_df from Step 3A (already filtered to MFP new construction)\n",
    "hpd_multifamily_finance_new_construction_for_matching_df = hpd_multifamily_finance_new_construction_df.copy()\n",
    "\n",
    "# Defensive: set of unique Project IDs for matching\n",
    "mfp_project_ids = set(hpd_multifamily_finance_new_construction_for_matching_df['Project ID'].unique())\n",
    "\n",
    "# Combine all DOB dataframes and normalize BIN columns\n",
    "all_dob_dfs = []\n",
    "\n",
    "# Normalize BIN columns in each DOB dataframe\n",
    "if not dob_bisweb_bin_df.empty:\n",
    "    if 'bin__' in dob_bisweb_bin_df.columns:\n",
    "        dob_bisweb_bin_df = dob_bisweb_bin_df.copy()\n",
    "        dob_bisweb_bin_df['bin_normalized'] = dob_bisweb_bin_df['bin__'].astype(str).str.replace('.0', '')\n",
    "    # Ensure BBL is displayed as a string, not float\n",
    "    if 'bbl' in dob_bisweb_bin_df.columns:\n",
    "        dob_bisweb_bin_df['bbl'] = dob_bisweb_bin_df['bbl'].apply(lambda x: str(int(float(x))).zfill(10) if pd.notna(x) else None)\n",
    "    all_dob_dfs.append(dob_bisweb_bin_df)\n",
    "\n",
    "if not dob_bisweb_bbl_df.empty:\n",
    "    if 'bin__' in dob_bisweb_bbl_df.columns:\n",
    "        dob_bisweb_bbl_df = dob_bisweb_bbl_df.copy()\n",
    "        dob_bisweb_bbl_df['bin_normalized'] = dob_bisweb_bbl_df['bin__'].astype(str).str.replace('.0', '')\n",
    "    elif 'bin' in dob_bisweb_bbl_df.columns:\n",
    "        dob_bisweb_bbl_df = dob_bisweb_bbl_df.copy()\n",
    "        dob_bisweb_bbl_df['bin_normalized'] = dob_bisweb_bbl_df['bin'].astype(str).str.replace('.0', '')\n",
    "    # Ensure BBL is displayed as a string, not float\n",
    "    if 'bbl' in dob_bisweb_bbl_df.columns:\n",
    "        dob_bisweb_bbl_df['bbl'] = dob_bisweb_bbl_df['bbl'].apply(lambda x: str(int(float(x))).zfill(10) if pd.notna(x) else None)\n",
    "    all_dob_dfs.append(dob_bisweb_bbl_df)\n",
    "\n",
    "if not dob_now_bin_df.empty:\n",
    "    if 'bin' in dob_now_bin_df.columns:\n",
    "        dob_now_bin_df = dob_now_bin_df.copy()\n",
    "        dob_now_bin_df['bin_normalized'] = dob_now_bin_df['bin'].astype(str).str.replace('.0', '')\n",
    "    # Ensure BBL is displayed as a string, not float\n",
    "    if 'bbl' in dob_now_bin_df.columns:\n",
    "        dob_now_bin_df['bbl'] = dob_now_bin_df['bbl'].apply(lambda x: str(int(float(x))).zfill(10) if pd.notna(x) else None)\n",
    "    all_dob_dfs.append(dob_now_bin_df)\n",
    "\n",
    "if not dob_now_bbl_df.empty:\n",
    "    if 'bin' in dob_now_bbl_df.columns:\n",
    "        dob_now_bbl_df = dob_now_bbl_df.copy()\n",
    "        dob_now_bbl_df['bin_normalized'] = dob_now_bbl_df['bin'].astype(str).str.replace('.0', '')\n",
    "    # Ensure BBL is displayed as a string, not float\n",
    "    if 'bbl' in dob_now_bbl_df.columns:\n",
    "        dob_now_bbl_df['bbl'] = dob_now_bbl_df['bbl'].apply(lambda x: str(int(float(x))).zfill(10) if pd.notna(x) else None)\n",
    "    all_dob_dfs.append(dob_now_bbl_df)\n",
    "\n",
    "# Use combined_dob_df from Step 3A if available, otherwise combine here\n",
    "if 'combined_dob_df' in globals() and not combined_dob_df.empty:\n",
    "    combined_dob_with_normalized_bbl_df = combined_dob_df.copy()\n",
    "    print(f'Total DOB records (from Step 3A): {len(combined_dob_with_normalized_bbl_df)}')\n",
    "elif all_dob_dfs:\n",
    "    combined_dob_with_normalized_bbl_df = pd.concat(all_dob_dfs, ignore_index=True)\n",
    "    print(f'Total DOB records: {len(combined_dob_with_normalized_bbl_df)}')\n",
    "else:\n",
    "    combined_dob_with_normalized_bbl_df = pd.DataFrame()\n",
    "    print('No DOB records found')\n",
    "\n",
    "# Prepare HPD data for matching - normalize BIN and ensure BBL is string\n",
    "hpd_multifamily_finance_new_construction_with_normalized_ids_df = hpd_multifamily_finance_new_construction_for_matching_df.copy()\n",
    "hpd_multifamily_finance_new_construction_with_normalized_ids_df['bin_normalized'] = hpd_multifamily_finance_new_construction_with_normalized_ids_df['BIN'].astype(str).str.replace('.0', '')\n",
    "hpd_multifamily_finance_new_construction_with_normalized_ids_df['bbl_normalized'] = hpd_multifamily_finance_new_construction_with_normalized_ids_df['BBL'].apply(lambda x: str(int(float(x))).zfill(10) if pd.notna(x) else None)\n",
    "\n",
    "# Join on BIN first\n",
    "if not combined_dob_with_normalized_bbl_df.empty and 'bin_normalized' in combined_dob_with_normalized_bbl_df.columns:\n",
    "    hpd_matched_on_bin_df = pd.merge(\n",
    "        hpd_multifamily_finance_new_construction_with_normalized_ids_df,\n",
    "        combined_dob_with_normalized_bbl_df[['bin_normalized']].drop_duplicates(),\n",
    "        on='bin_normalized',\n",
    "        how='inner'\n",
    "    )\n",
    "    matched_project_ids_bin = set(hpd_matched_on_bin_df['Project ID'].unique())\n",
    "    print(f'Projects matched on BIN: {len(matched_project_ids_bin)}')\n",
    "else:\n",
    "    matched_project_ids_bin = set()\n",
    "\n",
    "# Join on BBL for those that didn't match on BIN\n",
    "hpd_unmatched_on_bin_df = hpd_multifamily_finance_new_construction_with_normalized_ids_df[~hpd_multifamily_finance_new_construction_with_normalized_ids_df['Project ID'].isin(matched_project_ids_bin)]\n",
    "\n",
    "# Initialize BBL matching result\n",
    "matched_project_ids_bbl = set()\n",
    "\n",
    "# Reconstruct BBL in DOB data for sources that don't have it (like BISWEB)\n",
    "# Reconstruct BBL from borough, block, lot for records that don't have it\n",
    "def reconstruct_bbl(row):\n",
    "    if pd.isna(row.get('borough')) or pd.isna(row.get('block')) or pd.isna(row.get('lot')):\n",
    "        return None\n",
    "    borough_map = {'MANHATTAN': '1', 'BRONX': '2', 'BROOKLYN': '3', 'QUEENS': '4', 'STATEN ISLAND': '5'}\n",
    "    borough_code = borough_map.get(str(row['borough']).upper(), None)\n",
    "    if not borough_code:\n",
    "        return None\n",
    "    # Remove leading zeros from block/lot for BBL reconstruction\n",
    "    block_str = str(int(float(str(row['block']).replace('.0', ''))))\n",
    "    lot_str = str(int(float(str(row['lot']).replace('.0', ''))))\n",
    "    # Reconstruct: borough(1) + block(5) + lot(4) = 10 digits\n",
    "    bbl_str = borough_code + block_str.zfill(5) + lot_str.zfill(4)\n",
    "    return bbl_str.zfill(10)\n",
    "\n",
    "# Always reconstruct BBL for records that need it (BISWEB data doesn't have bbl column)\n",
    "combined_dob_with_normalized_bbl_df['bbl_reconstructed'] = combined_dob_with_normalized_bbl_df.apply(reconstruct_bbl, axis=1)\n",
    "# Normalize BBL in DOB data (use existing bbl or reconstructed)\n",
    "# Use bbl column if available, otherwise use reconstructed BBL\n",
    "if 'bbl' in combined_dob_with_normalized_bbl_df.columns:\n",
    "    # Use existing bbl column, normalized to 10 digits\n",
    "    combined_dob_with_normalized_bbl_df['bbl_normalized'] = combined_dob_with_normalized_bbl_df['bbl'].apply(lambda x: str(int(float(x))).zfill(10) if pd.notna(x) else None)\n",
    "    # Fill missing values with reconstructed BBL\n",
    "    if 'bbl_reconstructed' in combined_dob_with_normalized_bbl_df.columns:\n",
    "        combined_dob_with_normalized_bbl_df['bbl_normalized'] = combined_dob_with_normalized_bbl_df['bbl_normalized'].fillna(combined_dob_with_normalized_bbl_df['bbl_reconstructed'])\n",
    "elif 'bbl_reconstructed' in combined_dob_with_normalized_bbl_df.columns:\n",
    "    # Use reconstructed BBL if no bbl column exists\n",
    "    combined_dob_with_normalized_bbl_df['bbl_normalized'] = combined_dob_with_normalized_bbl_df['bbl_reconstructed']\n",
    "else:\n",
    "    combined_dob_with_normalized_bbl_df['bbl_normalized'] = None\n",
    "\n",
    "# Now match on BBL\n",
    "if 'bbl_normalized' in combined_dob_with_normalized_bbl_df.columns and combined_dob_with_normalized_bbl_df['bbl_normalized'].notna().any():\n",
    "    hpd_matched_on_bbl_df = pd.merge(\n",
    "        hpd_unmatched_on_bin_df,\n",
    "        combined_dob_with_normalized_bbl_df[['bbl_normalized']].drop_duplicates(),\n",
    "        on='bbl_normalized',\n",
    "        how='inner'\n",
    "    )\n",
    "    matched_project_ids_bbl = set(hpd_matched_on_bbl_df['Project ID'].unique())\n",
    "    print(f'Projects matched on BBL (fallback): {len(matched_project_ids_bbl)}')\n",
    "else:\n",
    "    matched_project_ids_bbl = set()\n",
    "    print('No BBL data available for matching')\n",
    "\n",
    "# Combine all matched project IDs\n",
    "dob_matched_project_ids = matched_project_ids_bin | matched_project_ids_bbl\n",
    "\n",
    "# Find projects without DOB matches\n",
    "mfp_projects_without_dob = mfp_project_ids - dob_matched_project_ids\n",
    "\n",
    "print(f'\\nTotal Multifamily Finance Program new construction projects: {len(mfp_project_ids)}')\n",
    "print(f'Projects with DOB matches: {len(dob_matched_project_ids)}')\n",
    "print(f'Number of these with NO DOB row in any table: {len(mfp_projects_without_dob)}')\n",
    "\n",
    "# Debug: show a sample of matched and unmatched projects\n",
    "if len(matched_project_ids_bin) > 0:\n",
    "    print(f'\\nSample matched on BIN: {list(matched_project_ids_bin)[:3]}')\n",
    "if len(matched_project_ids_bbl) > 0:\n",
    "    print(f'Sample matched on BBL: {list(matched_project_ids_bbl)[:3]}')\n",
    "if len(mfp_projects_without_dob) > 0:\n",
    "    print(f'Sample unmatched: {list(mfp_projects_without_dob)[:3]}')\n",
    "\n",
    "# DEBUG: Analyze a sample project to understand matching\n",
    "if len(mfp_projects_without_dob) > 0:\n",
    "    sample_project_id = list(mfp_projects_without_dob)[0]\n",
    "    sample_project = hpd_multifamily_finance_new_construction_for_matching_df[hpd_multifamily_finance_new_construction_for_matching_df['Project ID'] == sample_project_id]\n",
    "    print(f'\\n=== DEBUG: Sample unmatched project ===')\n",
    "    print(f'Project ID: {sample_project_id}')\n",
    "    print(f'Number of buildings in project: {len(sample_project)}')\n",
    "    sample_bins = sample_project['BIN'].dropna().astype(str).str.replace('.0', '').tolist()\n",
    "    sample_bbls = sample_project['BBL'].dropna().apply(lambda x: str(int(float(x))).zfill(10) if pd.notna(x) else None).tolist()\n",
    "    print(f'BINs in project: {sample_bins[:5]}')\n",
    "    print(f'BBLs in project: {sample_bbls[:5]}')\n",
    "    \n",
    "    # Check if these BINs/BBLs exist in DOB data\n",
    "    if not combined_dob_with_normalized_bbl_df.empty:\n",
    "        if 'bin_normalized' in combined_dob_with_normalized_bbl_df.columns:\n",
    "            dob_bins = set(combined_dob_with_normalized_bbl_df['bin_normalized'].dropna().astype(str).unique())\n",
    "            matching_bins = []\n",
    "            for b in sample_bins:\n",
    "                if b in dob_bins:\n",
    "                    matching_bins.append(b)\n",
    "            print(f'BINs found in DOB data: {matching_bins[:5] if matching_bins else \"None\"}')\n",
    "        if 'bbl' in combined_dob_with_normalized_bbl_df.columns:\n",
    "            dob_bbls = set(combined_dob_with_normalized_bbl_df['bbl'].dropna().apply(lambda x: str(int(float(x))).zfill(10) if pd.notna(x) else None).unique())\n",
    "            matching_bbls = []\n",
    "            for b in sample_bbls:\n",
    "                if b in dob_bbls:\n",
    "                    matching_bbls.append(b)\n",
    "            print(f'BBLs found in DOB data: {matching_bbls[:5] if matching_bbls else \"None\"}')\n",
    "# Show the head of the table of unmatched projects (project-level)\n",
    "if len(mfp_projects_without_dob) > 0:\n",
    "    print(\"\\nHead of unmatched Multifamily Finance Program new construction projects:\")\n",
    "    hpd_multifamily_finance_new_construction_unmatched_projects_df = hpd_multifamily_finance_new_construction_for_matching_df[hpd_multifamily_finance_new_construction_for_matching_df['Project ID'].isin(mfp_projects_without_dob)].copy()\n",
    "    # Ensure BBL is displayed as a string, not float\n",
    "    if 'BBL' in hpd_multifamily_finance_new_construction_unmatched_projects_df.columns:\n",
    "        hpd_multifamily_finance_new_construction_unmatched_projects_df['BBL'] = hpd_multifamily_finance_new_construction_unmatched_projects_df['BBL'].apply(lambda x: str(int(float(x))).zfill(10) if pd.notna(x) else None)\n",
    "    excluded_cols = [\n",
    "        \"Lot Area\", \"Available Units\", \"Privately Financed Units\", \"Extremely Low Income Units\",\n",
    "        \"Very Low Income Units\", \"Low Income Units\", \"Moderate Income Units\", \"Middle Income Units\",\n",
    "        \"Studio Units\", \"One Bedroom Units\", \"Two Bedroom Units\", \"Three Bedroom Units\",\n",
    "        \"Four Bedroom Units\", \"Five Bedroom Units\", \"Six Bedroom Units\", \"Unknown Bedroom Units\",\n",
    "    ][:15]  # Limit extra-wide tables in notebook\n",
    "    display_cols = []\n",
    "    for c in hpd_multifamily_finance_new_construction_unmatched_projects_df.columns:\n",
    "        if c not in excluded_cols:\n",
    "            display_cols.append(c)\n",
    "    display(hpd_multifamily_finance_new_construction_unmatched_projects_df[display_cols].head(10))\n",
    "else:\n",
    "    print(\"\\nAll Multifamily Finance Program projects matched to DOB data!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paid', 'approved_date', 'approved', 'assigned']\n",
      "\n",
      "Joined HPD MFP new construction table with DOB earliest milestone dates (BIN‚ÜíBBL fallback).\n",
      "  Project ID      BIN         BBL earliest_dob_date\n",
      "0      44218  1054682  1017907501        2017-12-02\n",
      "1      44223  3000000  3015560003        2009-06-18\n",
      "2      44223  3000000  3017090009        2009-06-24\n",
      "3      44223  3000000  3017090028        2009-06-24\n",
      "4      44223  3000000  3015560007        2009-06-18\n",
      "5      44225  2129098  2022927501        2000-08-31\n",
      "6      44225  2000000  2022927501               NaT\n",
      "7      44239  1090253  1019110061        2014-03-18\n",
      "8      44256  1090749  1018637501        2017-10-16\n",
      "9      44280  2127429  2023837501        2014-09-05\n",
      "\n",
      "Count of HPD MFP new construction rows without an earliest DOB milestone date: 74\n"
     ]
    }
   ],
   "source": [
    "# Join HPD Multifamily Finance new construction rows to DOB data,\n",
    "# first on BIN, then using BBL as a backup for rows without a BIN match.\n",
    "# For each HPD row, add the earliest of DOB's 'paid', 'applied', or 'approved' date\n",
    "# (whichever is earliest/present among these columns in the DOB data).\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def _get_earliest_date(row, date_cols):\n",
    "    dates = [pd.to_datetime(row[col], errors='coerce') for col in date_cols if col in row and pd.notna(row[col])]\n",
    "    return min(dates) if dates else pd.NaT\n",
    "\n",
    "# Use the existing bbl_normalized column which includes both original bbl and reconstructed BBL\n",
    "# If bbl_normalized doesn't exist, create it from the bbl column\n",
    "dob_df = combined_dob_with_normalized_bbl_df.copy()\n",
    "if 'bbl_normalized' not in dob_df.columns:\n",
    "    # Fallback: create bbl_normalized from bbl column if it doesn't exist\n",
    "    dob_df['bbl_normalized'] = dob_df['bbl'].apply(lambda x: str(int(float(x))).zfill(10) if pd.notna(x) else None)\n",
    "else:\n",
    "    # Ensure bbl_normalized is properly formatted as string (10 digits, zero-padded)\n",
    "    def format_bbl(x):\n",
    "        if pd.isna(x) or x is None:\n",
    "            return None\n",
    "        try:\n",
    "            # Try to convert to int then string, then pad\n",
    "            return str(int(float(x))).zfill(10)\n",
    "        except (ValueError, TypeError):\n",
    "            # If it's already a string, check if it's valid\n",
    "            x_str = str(x).strip()\n",
    "            if x_str in ('None', 'nan', ''):\n",
    "                return None\n",
    "            # If it's already a 10-digit string, return as is\n",
    "            if x_str.isdigit() and len(x_str) <= 10:\n",
    "                return x_str.zfill(10)\n",
    "            return None\n",
    "    dob_df['bbl_normalized'] = dob_df['bbl_normalized'].apply(format_bbl)\n",
    "\n",
    "# The date columns that might contain the milestone dates\n",
    "# Collect BISWEB milestone columns\n",
    "bisweb_date_cols = []\n",
    "for c in ['pre-filing', 'pre filing', 'pre- filing', 'paid', 'fully paid', 'assigned', 'approved', 'fully permitted']:\n",
    "    matches = [col for col in dob_df.columns if col.lower().startswith(c)]\n",
    "    bisweb_date_cols.extend(matches)\n",
    "\n",
    "# DOB NOW milestone columns: exactly 'Filing Date' and 'First Approved Date', case-insensitive\n",
    "dobnow_date_cols = []\n",
    "for col in dob_df.columns:\n",
    "    if col.strip().lower() in ['filing date', 'first approved date']:\n",
    "        dobnow_date_cols.append(col)\n",
    "\n",
    "# Combine, de-duplicate\n",
    "date_cols = list(set(bisweb_date_cols + dobnow_date_cols))\n",
    "print(date_cols)\n",
    "\n",
    "# Find earliest relevant DOB milestone date per BIN and BBL\n",
    "dob_bin_dates = dob_df.copy()\n",
    "dob_bin_dates['earliest_dob_date'] = dob_bin_dates.apply(lambda row: _get_earliest_date(row, date_cols), axis=1)\n",
    "\n",
    "# Reduce DOB to earliest date per BIN and per BBL\n",
    "# Filter out None/NaN BBLs before grouping to avoid grouping on None values\n",
    "dob_bin_min = dob_bin_dates.groupby('bin_normalized', as_index=False)['earliest_dob_date'].min()\n",
    "dob_bbl_min = dob_bin_dates[dob_bin_dates['bbl_normalized'].notna()].groupby('bbl_normalized', as_index=False)['earliest_dob_date'].min()\n",
    "\n",
    "# Prepare HPD for matching\n",
    "hpd_df = hpd_multifamily_finance_new_construction_df.copy()\n",
    "hpd_df['BIN_str'] = hpd_df['BIN'].dropna().astype(str).str.replace('.0', '')\n",
    "hpd_df['BBL_str'] = hpd_df['BBL'].apply(lambda x: str(int(float(x))).zfill(10) if pd.notna(x) else None)\n",
    "\n",
    "# Merge on BIN first\n",
    "hpd_with_date = pd.merge(\n",
    "    hpd_df,\n",
    "    dob_bin_min.rename(columns={'bin_normalized': 'BIN_str'}),\n",
    "    how='left',\n",
    "    on='BIN_str'\n",
    ")\n",
    "# For rows without a BIN match, try to fill using a BBL match\n",
    "no_bin_match_mask = hpd_with_date['earliest_dob_date'].isna()\n",
    "if no_bin_match_mask.any():\n",
    "    to_fill = hpd_with_date.loc[no_bin_match_mask, ['BBL_str']]\n",
    "    filled = pd.merge(\n",
    "        to_fill,\n",
    "        dob_bbl_min.rename(columns={'bbl_normalized': 'BBL_str'}),\n",
    "        how='left',\n",
    "        on='BBL_str'\n",
    "    )\n",
    "    # Fill only where not matched by BIN but matched by BBL\n",
    "    hpd_with_date.loc[no_bin_match_mask, 'earliest_dob_date'] = filled['earliest_dob_date'].values\n",
    "\n",
    "# Add result to our HPD dataframe\n",
    "hpd_multifamily_finance_new_construction_with_dob_date_df = hpd_with_date\n",
    "\n",
    "print(\"\\nJoined HPD MFP new construction table with DOB earliest milestone dates (BIN‚ÜíBBL fallback).\")\n",
    "print(hpd_multifamily_finance_new_construction_with_dob_date_df[['Project ID', 'BIN', 'BBL', 'earliest_dob_date']].head(10))\n",
    "num_missing_earliest_dob_date = hpd_multifamily_finance_new_construction_with_dob_date_df['earliest_dob_date'].isna().sum()\n",
    "print(f\"\\nCount of HPD MFP new construction rows without an earliest DOB milestone date: {num_missing_earliest_dob_date}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèõÔ∏è Step 4: Query Certificate of Occupancy\n",
    "\n",
    "Search for Certificate of Occupancy filings.\n",
    "\n",
    "**Depends on:** Step 2\n",
    "**Options:**\n",
    "- Set `skip_co = True` to use existing CO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3B Configuration\n",
    "skip_co = False  # Set to True to use existing CO data\n",
    "co_output_path = None  # Custom CO output path\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 3B: QUERY CERTIFICATE OF OCCUPANCY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Extract BINs from hpd_multifamily_finance_new_construction_df (in memory from Step 3A)\n",
    "bins_list = _extract_bins_from_df(hpd_multifamily_finance_new_construction_df)\n",
    "print(f\"\\nüìã Extracted {len(bins_list)} BINs from filtered dataset\")\n",
    "\n",
    "if skip_co:\n",
    "    print(\"‚è≠Ô∏è Using existing CO data\")\n",
    "    # Look for existing CO files\n",
    "    co_output = Path(co_output_path) if co_output_path else Path(\n",
    "        f\"data/processed/workflow_bins_co_filings.csv\"\n",
    "    )\n",
    "    alt_co_path = Path(f\"data/external/workflow_bins_co_filings.csv\")\n",
    "    if co_output.exists():\n",
    "        print(f\"üìÅ Using existing CO data at {co_output}\")\n",
    "        co_filings_df = pd.read_csv(co_output)\n",
    "    elif alt_co_path.exists():\n",
    "        print(f\"üìÅ Using existing CO data from external folder: {alt_co_path}\")\n",
    "        co_filings_df = pd.read_csv(alt_co_path)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No existing CO data found\")\n",
    "        co_filings_df = None\n",
    "else:\n",
    "    print(f\"üèõÔ∏è Querying CO APIs using {len(bins_list)} BINs (in memory)\")\n",
    "    co_filings_df = _query_co_filings_from_bins(bins_list, output_path=None)\n",
    "\n",
    "# Display CO data if available\n",
    "if co_filings_df is not None:\n",
    "    print(f\"üìä Certificate of Occupancy Data: {co_filings_df.shape[0]} records\")\n",
    "    print(\"Columns:\")\n",
    "    for col in co_filings_df.columns:\n",
    "        print(f\"  - {col}\")\n",
    "    \n",
    "    print(\"\\nüìä Sample CO Data:\")\n",
    "    display(co_filings_df.head())\n",
    "    \n",
    "    # Show some statistics\n",
    "    if \"issue_date\" in co_filings_df.columns:\n",
    "        print(\"\\nüìà CO Issue Date Statistics:\")\n",
    "        display(co_filings_df[\"issue_date\"].describe())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No CO data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 5: Generate Timelines and Charts\n",
    "\n",
    "Create timeline visualizations from enriched data.\n",
    "\n",
    "**Depends on:** Steps 2, 3A\n",
    "**Options:**\n",
    "- Set `skip_join = True` to skip timeline creation\n",
    "- Set `skip_charts = True` to skip chart generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 Configuration\n",
    "skip_join = False   # Set to True to skip timeline creation\n",
    "skip_charts = False # Set to True to skip chart generation\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 4: GENERATE TIMELINES AND CHARTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if skip_join:\n",
    "    print(\"‚è≠Ô∏è Skipping timeline join step.\")\n",
    "else:\n",
    "    # Check if we have the required dataframes in memory\n",
    "    if 'combined_dob_df' not in globals() or combined_dob_df.empty:\n",
    "        print(\"‚ö†Ô∏è No DOB data available; skipping timeline creation.\")\n",
    "    else:\n",
    "        print(\"üîó Building timelines from in-memory dataframes...\")\n",
    "        \n",
    "        # Create temporary files for timeline function (it expects file paths)\n",
    "        import tempfile\n",
    "        temp_building = Path(tempfile.mktemp(suffix=\"_buildings.csv\"))\n",
    "        temp_dob = Path(tempfile.mktemp(suffix=\"_dob.csv\"))\n",
    "        temp_co = Path(tempfile.mktemp(suffix=\"_co.csv\")) if 'co_filings_df' in globals() and co_filings_df is not None and not co_filings_df.empty else None\n",
    "        \n",
    "        # Write dataframes to temporary files\n",
    "        hpd_multifamily_finance_new_construction_df.to_csv(temp_building, index=False)\n",
    "        combined_dob_df.to_csv(temp_dob, index=False)\n",
    "        if temp_co:\n",
    "            co_filings_df.to_csv(temp_co, index=False)\n",
    "        \n",
    "        try:\n",
    "            create_separate_timelines(\n",
    "                str(temp_building),\n",
    "                str(temp_dob),\n",
    "                str(temp_co) if temp_co else None,\n",
    "            )\n",
    "            \n",
    "            # Load timeline results into dataframes\n",
    "            # Function replaces .csv with _hpd_financed_timeline.csv\n",
    "            hpd_timeline_path = Path(str(temp_building).replace('.csv', '_hpd_financed_timeline.csv'))\n",
    "            private_timeline_path = Path(str(temp_building).replace('.csv', '_privately_financed_timeline.csv'))\n",
    "            \n",
    "            if hpd_timeline_path.exists():\n",
    "                hpd_timeline_df = pd.read_csv(hpd_timeline_path)\n",
    "                print(f\"\\nüìä HPD Financed Timeline Data ({hpd_timeline_df.shape[0]} records):\")\n",
    "                display(hpd_timeline_df.head())\n",
    "                \n",
    "                if \"Event\" in hpd_timeline_df.columns:\n",
    "                    print(\"\\nüìà Event Types in HPD Timeline:\")\n",
    "                    display(hpd_timeline_df[\"Event\"].value_counts())\n",
    "            \n",
    "            if private_timeline_path.exists():\n",
    "                private_timeline_df = pd.read_csv(private_timeline_path)\n",
    "                print(f\"\\nüìä Privately Financed Timeline Data ({private_timeline_df.shape[0]} records):\")\n",
    "                display(private_timeline_df.head())\n",
    "                \n",
    "                if \"Event\" in private_timeline_df.columns:\n",
    "                    print(\"\\nüìà Event Types in Private Timeline:\")\n",
    "                    display(private_timeline_df[\"Event\"].value_counts())\n",
    "        finally:\n",
    "            # Clean up temporary files\n",
    "            if temp_building.exists():\n",
    "                temp_building.unlink()\n",
    "            if temp_dob.exists():\n",
    "                temp_dob.unlink()\n",
    "            if temp_co and temp_co.exists():\n",
    "                temp_co.unlink()\n",
    "\n",
    "if skip_charts:\n",
    "    print(\"‚è≠Ô∏è Skipping chart generation.\")\n",
    "else:\n",
    "    # Charts\n",
    "    print(\"\\nüìà Generating charts...\")\n",
    "    # Charts would need timeline files, which are created above\n",
    "    # For now, skip chart generation if timelines weren't created\n",
    "    if 'hpd_timeline_df' in locals() or 'private_timeline_df' in locals():\n",
    "        print(\"‚ö†Ô∏è Chart generation from in-memory dataframes not yet implemented.\")\n",
    "        print(\"   Timeline dataframes are available in memory (hpd_timeline_df, private_timeline_df)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No timeline data available for chart generation.\")\n",
    "\n",
    "print(\"\\n‚úÖ Step 4 complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Final Summary\n",
    "\n",
    "Generate data quality report and workflow summary.\n",
    "\n",
    "**Optional:** Run this at the end to see final statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä FINAL SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüéâ WORKFLOW COMPLETED!\")\n",
    "\n",
    "# Summary of what we accomplished\n",
    "print(\"\\nüìã WORKFLOW SUMMARY:\")\n",
    "try:\n",
    "    print(f\"‚Ä¢ HPD Records Processed (New Construction): {len(hpd_new_construction_df):,}\")\n",
    "except NameError:\n",
    "    print(\"‚Ä¢ HPD Records: Step 1 not run\")\n",
    "try:\n",
    "    print(f\"‚Ä¢ HPD Multifamily Finance Program (New Construction): {len(hpd_multifamily_finance_new_construction_df):,}\")\n",
    "except NameError:\n",
    "    print(\"‚Ä¢ HPD Multifamily Finance Program: Step 3A not run\")\n",
    "try:\n",
    "    if 'combined_dob_df' in globals() and combined_dob_df is not None and not combined_dob_df.empty:\n",
    "        print(f\"‚Ä¢ DOB Filings Found: {len(combined_dob_df):,}\")\n",
    "    else:\n",
    "        print(\"‚Ä¢ DOB Filings: No data\")\n",
    "except NameError:\n",
    "    print(\"‚Ä¢ DOB Filings: Step 3A not run\")\n",
    "try:\n",
    "    if 'co_filings_df' in globals() and co_filings_df is not None and not co_filings_df.empty:\n",
    "        print(f\"‚Ä¢ CO Filings Found: {len(co_filings_df):,}\")\n",
    "    else:\n",
    "        print(\"‚Ä¢ CO Filings: No data\")\n",
    "except NameError:\n",
    "    print(\"‚Ä¢ CO Filings: Step 3B not run\")\n",
    "\n",
    "print(\"\\n‚úÖ Notebook workflow complete!\")\n",
    "print(\"Each step showed dataframe views for inspection.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
